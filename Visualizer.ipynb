{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import nibabel as nib\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal, stats\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = './reports/low_net3D_1_all/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(man):\n",
    "    base_results = np.load('{}/{}/base_losses.npy'.format(checkpoint_name, man))\n",
    "    net_results = np.load('{}/{}/net_losses.npy'.format(checkpoint_name, man))\n",
    "    frame_index_list = np.load('{}/{}/frame_index_list.npy'.format(checkpoint_name, man))\n",
    "    slice_index_list = np.load('{}/{}/slice_index_list.npy'.format(checkpoint_name, man))\n",
    "    total_sum_of_squares = np.load('{}/{}/base_test_mean_losses.npy'.format(checkpoint_name, man))\n",
    "    residual_loss_list = np.load('{}/{}/residual_loss_list.npy'.format(checkpoint_name, man))\n",
    "    \n",
    "    net_predictions = np.load('{}/{}/net_predictions.npy'.format(checkpoint_name, man))\n",
    "    gt_predictions = np.load('{}/{}/gt_predictions.npy'.format(checkpoint_name, man))\n",
    "    \n",
    "    \n",
    "    base_loss = np.sum(base_results)\n",
    "    net_loss = np.sum(net_results)\n",
    "    r2 = 1 - net_loss/base_loss\n",
    "    \n",
    "    slice_losses = np.zeros([30, 64, 64])\n",
    "    slice_base_losses = np.zeros([30, 64, 64])\n",
    "    slice_total_squares = np.zeros([30, 64, 64])\n",
    "    residual_loss_num = np.zeros([30, 64, 64])\n",
    "    residual_loss_denum = np.zeros([30, 64, 64])\n",
    "    for i, slice_indx in enumerate(slice_index_list):\n",
    "        slice_losses[slice_indx] += net_results[i] \n",
    "        slice_base_losses[slice_indx] += base_results[i]\n",
    "        slice_total_squares[slice_indx] += total_sum_of_squares[i]\n",
    "        residual_loss_num[slice_indx] += (net_predictions[i] - gt_predictions[i])**2\n",
    "        residual_loss_denum[slice_indx] += (gt_predictions[i])**2\n",
    "\n",
    "    for i in range(30):\n",
    "        slice_losses[i] /= np.sum(slice_index_list == i)\n",
    "        slice_base_losses[i] /= np.sum(slice_index_list == i)\n",
    "        slice_total_squares[i] /= np.sum(slice_index_list == i)\n",
    "    residual_loss = np.sqrt(residual_loss_num/(residual_loss_denum + 1e-9))\n",
    "    return r2, slice_losses, slice_base_losses, slice_total_squares, residual_loss\n",
    "\n",
    "def get_voxel_predictions(man, slice, indx1, indx2, slice_index_list=None, net_predictions=None, gt_predictions=None):\n",
    "    if slice_index_list is None:\n",
    "        slice_index_list = np.load('{}/{}/slice_index_list.npy'.format(checkpoint_name, man))\n",
    "    if net_predictions is None:\n",
    "        net_predictions = np.load('{}/{}/net_predictions.npy'.format(checkpoint_name, man))\n",
    "    if gt_predictions is None:\n",
    "        gt_predictions = np.load('{}/{}/gt_predictions.npy'.format(checkpoint_name, man))\n",
    "    \n",
    "    net_voxel_preds = []\n",
    "    gt_voxel_preds = []\n",
    "    for i in range(len(slice_index_list)):\n",
    "        if slice_index_list[i] != slice:\n",
    "            continue\n",
    "        \n",
    "        net_voxel_preds.append(net_predictions[i, indx1, indx2])\n",
    "        gt_voxel_preds.append(gt_predictions[i, indx1, indx2])\n",
    "        \n",
    "    return net_voxel_preds, gt_voxel_preds\n",
    "\n",
    "def get_correlations(man):\n",
    "    slice_index_list = np.load('{}/{}/slice_index_list.npy'.format(checkpoint_name, man))\n",
    "    net_predictions = np.load('{}/{}/net_predictions.npy'.format(checkpoint_name, man))\n",
    "    gt_predictions = np.load('{}/{}/gt_predictions.npy'.format(checkpoint_name, man))\n",
    "    \n",
    "    result = np.zeros([30, 64, 64])\n",
    "    for s in range(30):\n",
    "        for i in range(64):\n",
    "            for j in range(64):\n",
    "                p, q = get_voxel_predictions(man, s, i, j, slice_index_list, net_predictions, gt_predictions)\n",
    "                result[s, i, j], _ = stats.pearsonr(p, q)\n",
    "    return result\n",
    "\n",
    "def get_grad(man):\n",
    "    return np.load('{}/{}/grad_statistic.npy'.format(checkpoint_name, man))[:, 0].mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics_full(i):\n",
    "    fmri_path = '../../data/fMRI/'\n",
    "    fmri = read_img(os.path.join(fmri_path, str(all_people[i])))\n",
    "    net_predictions = np.load('{}/{}/net_predictions.npy'.format(checkpoint_name, str(all_people[i])))\n",
    "    gt_predictions = np.load('{}/{}/gt_predictions.npy'.format(checkpoint_name, str(all_people[i])))\n",
    "    slice_index_list = np.load('{}/{}/slice_index_list.npy'.format(checkpoint_name, str(all_people[i])))\n",
    "    fmri_mean = fmri.mean(-1) / 4095 * 100\n",
    "    num = np.zeros([30, 64, 64])\n",
    "    denum = np.zeros([30, 64, 64])\n",
    "\n",
    "    for i, indx in enumerate(slice_index_list):\n",
    "        mean = fmri_mean[..., indx]\n",
    "        num[indx] += (net_predictions[i] - gt_predictions[i]) ** 2\n",
    "        denum[indx] += (gt_predictions[i] - mean) ** 2\n",
    "    stats = np.sqrt(num / (denum + 1e-9))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics_train(i):\n",
    "    fmri_path = '../../data/fMRI/'\n",
    "    fmri = read_img(os.path.join(fmri_path, str(all_people[i])))\n",
    "    net_predictions = np.load('{}/{}/net_predictions.npy'.format(checkpoint_name, str(all_people[i])))\n",
    "    gt_predictions = np.load('{}/{}/gt_predictions.npy'.format(checkpoint_name, str(all_people[i])))\n",
    "    slice_index_list = np.load('{}/{}/slice_index_list.npy'.format(checkpoint_name, str(all_people[i])))\n",
    "    fmri_mean = fmri[..., :210].mean(-1) / 4095 * 100\n",
    "    num = np.zeros([30, 64, 64])\n",
    "    denum = np.zeros([30, 64, 64])\n",
    "\n",
    "    for i, indx in enumerate(slice_index_list):\n",
    "        mean = fmri_mean[..., indx]\n",
    "        num[indx] += (net_predictions[i] - gt_predictions[i]) ** 2\n",
    "        denum[indx] += (gt_predictions[i] - mean) ** 2\n",
    "    stats = np.sqrt(num / (denum + 1e-9))\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    path = path[:-7]\n",
    "    files = os.listdir(path)\n",
    "    for file in files:\n",
    "        if file[-12:] == 'cross.nii.gz':\n",
    "            return nib.load(os.path.join(path, file)).get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_path = '../../data/fMRI/'\n",
    "all_people = ['40/models', '49/models', '37/models', '36/models', '50/models', '47/models', '32/models', '48/models', '46/models', '35/models', '42/models', '43/models', '39/models', '44/models', '38/models', '41/models', '45/models']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 11):\n",
    "    print(i/10, end=' & ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    print(all_people[i],  end=' & ')\n",
    "    s = get_statistics_train(i)\n",
    "    for i in [4, 6, 8, 10]:\n",
    "        print(\"{0:.6f}\".format((s < i/10).mean()), end=' & ')\n",
    "    print(\"{0:.6f}\".format((s < 1).mean()), end=' \\\\\\\\ ')\n",
    "    print()\n",
    "    print('\\hline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    print(all_people[i],  end=' & ')\n",
    "    s = get_statistics_full(i)\n",
    "    for i in [4, 6, 8, 10]:\n",
    "        print(\"{0:.6f}\".format((s < i/10).mean()), end=' & ')\n",
    "    print(\"{0:.6f}\".format((s < 1).mean()), end=' \\\\\\\\ ')\n",
    "    print()\n",
    "    print('\\hline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_list = [get_grad(man) for man in all_people]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.array([   0.        ,    3.96825397,    7.93650794,   11.9047619 ,\n",
    "         15.87301587,   19.84126984,   23.80952381,   27.77777778,\n",
    "         31.74603175,   35.71428571,   39.68253968,   43.65079365,\n",
    "         47.61904762,   51.58730159,   55.55555556,   59.52380952,\n",
    "         63.49206349,   67.46031746,   71.42857143,   75.3968254 ,\n",
    "         79.36507937,   83.33333333,   87.3015873 ,   91.26984127,\n",
    "         95.23809524,   99.20634921,  103.17460317,  107.14285714,\n",
    "        111.11111111,  115.07936508,  119.04761905,  123.01587302])\n",
    "\n",
    "t = np.array([  0.   ,   0.128,   0.256,   0.384,   0.512,   0.64 ,   0.768,\n",
    "         0.896,   1.024,   1.152,   1.28 ,   1.408,   1.536,   1.664,\n",
    "         1.792,   1.92 ,   2.048,   2.176,   2.304,   2.432,   2.56 ,\n",
    "         2.688,   2.816,   2.944,   3.072,   3.2  ,   3.328,   3.456,\n",
    "         3.584,   3.712,   3.84 ,   3.968,   4.096,   4.224,   4.352,\n",
    "         4.48 ,   4.608,   4.736,   4.864,   4.992,   5.12 ,   5.248,\n",
    "         5.376,   5.504,   5.632,   5.76 ,   5.888,   6.016,   6.144,\n",
    "         6.272,   6.4  ,   6.528,   6.656,   6.784,   6.912,   7.04 ,\n",
    "         7.168,   7.296,   7.424,   7.552,   7.68 ,   7.808,   7.936,\n",
    "         8.064,   8.192,   8.32 ,   8.448,   8.576,   8.704,   8.832,\n",
    "         8.96 ,   9.088,   9.216,   9.344,   9.472,   9.6  ,   9.728,\n",
    "         9.856,   9.984,  10.112,  10.24 ,  10.368,  10.496,  10.624,\n",
    "        10.752,  10.88 ,  11.008,  11.136,  11.264,  11.392,  11.52 ,\n",
    "        11.648,  11.776,  11.904,  12.032,  12.16 ,  12.288,  12.416,\n",
    "        12.544,  12.672,  12.8  ,  12.928,  13.056,  13.184,  13.312,\n",
    "        13.44 ,  13.568,  13.696,  13.824,  13.952,  14.08 ,  14.208,\n",
    "        14.336,  14.464,  14.592,  14.72 ,  14.848,  14.976,  15.104,\n",
    "        15.232,  15.36 ,  15.488,  15.616,  15.744,  15.872,  16.   ,\n",
    "        16.128,  16.256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance(man, threshold):\n",
    "    stats = get_statistics_train(man)\n",
    "    center_points = [14.5, 31.5, 31.5]\n",
    "    scores = {}\n",
    "    for i in range(30):\n",
    "        for j in range(64):\n",
    "            for k in range(64):\n",
    "                dist = (120/30*(i - center_points[0]))**2 \\\n",
    "                + (210/64*(j - center_points[1]))**2\\\n",
    "                + (210/64*(k - center_points[2]))**2\n",
    "                if dist not in scores:\n",
    "                    scores[dist] = []\n",
    "                scores[dist].append(stats[i, j, k] < threshold)\n",
    "\n",
    "    for key in scores:\n",
    "        scores[key] = np.mean(scores[key])\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_distance(0, .6)\n",
    "\n",
    "center_points = [14.5, 31.5, 31.5]\n",
    "distances = np.zeros([30, 64, 64])\n",
    "for i in range(30):\n",
    "    for j in range(64):\n",
    "        for k in range(64):\n",
    "            dist = (120/30*(i - center_points[0]))**2 \\\n",
    "            + (210/64*(j - center_points[1]))**2\\\n",
    "            + (210/64*(k - center_points[2]))**2\n",
    "            distances[i, j, k] = scores[dist]\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_coll = np.concatenate([distances[i] for i in range(30)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10, 100])\n",
    "#plt.imshow((dist_coll < 70) & (dist_coll > 50))\n",
    "plt.imshow(dist_coll)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ./plots\n",
    "!mkdir ./plots/mean_grads\n",
    "!mkdir ./plots/percentage_distance\n",
    "!mkdir ./plots/percentage_distance/smoothed\n",
    "!mkdir ./plots/percentage_distance/raw\n",
    "!mkdir ./plots/treshold_visualization\n",
    "!mkdir ./plots/distance_metric/\n",
    "!mkdir ./plots/distance_metric/voxel_tresholds\n",
    "!mkdir ./plots/distance_metric/smoothed\n",
    "!mkdir ./plots/distance_metric/raw\n",
    "!mkdir ./plots/distance_metric/voxel_masks\n",
    "!mkdir ./plots/clipped_metric/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_people():\n",
    "    stat_list = []\n",
    "    for i in range(len(all_people)):\n",
    "        s = get_statistics_train(i)\n",
    "        stat_list.append(-(s < .6).mean())\n",
    "    return np.argsort(stat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_rate = get_sorted_people()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    plt.pcolormesh(t, f, np.abs(grad_list[i]).mean(0), vmin=0, cmap='plasma')\n",
    "    plt.title(\"mean abs gradient input man {}\".format(all_people[i][:-7]))\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('Frequency [Hz]')\n",
    "    plt.xlabel('Time [sec]')\n",
    "    plt.savefig('./plots/mean_grads/mean_gradient_subject_{}_rate_{}.png'.format(all_people[i][:-7], subject_rate[i]))\n",
    "    plt.show()\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_percentage_distance(man, threshold):\n",
    "    stats = get_statistics_train(man)\n",
    "    center_points = [14.5, 31.5, 31.5]\n",
    "    scores = {}\n",
    "    for i in range(30):\n",
    "        for j in range(64):\n",
    "            for k in range(64):\n",
    "                dist = (120/30*(i - center_points[0]))**2 \\\n",
    "                + (210/64*(j - center_points[1]))**2\\\n",
    "                + (210/64*(k - center_points[2]))**2\n",
    "                if dist not in scores:\n",
    "                    scores[dist] = []\n",
    "                scores[dist].append(stats[i, j, k] < threshold)\n",
    "\n",
    "    for key in scores:\n",
    "        scores[key] = np.mean(scores[key])\n",
    "\n",
    "    keys, values = [], []\n",
    "    for key in scores:\n",
    "        keys.append(np.sqrt(key))\n",
    "        values.append(scores[key])\n",
    "    values = np.array(values)\n",
    "    keys = np.array(keys)\n",
    "\n",
    "    argsort = np.argsort(keys)\n",
    "\n",
    "    plt.plot(keys[argsort], values[argsort])\n",
    "    plt.title(\"Voxel percentage/Distance subject {} threshold {}\".format(all_people[man][:-7], threshold))\n",
    "    plt.ylabel('Voxel percentage')\n",
    "    plt.xlabel('Distance [mm]')\n",
    "    plt.savefig('./plots/percentage_distance/raw/percentage_distance_subject_{}_rate_{}.png'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(keys[argsort], signal.savgol_filter(values[argsort], 53, 10))\n",
    "    plt.title(\"Savgol Filter for voxel percentage/Distance subject {} threshold {}\".format(all_people[man][:-7], threshold))\n",
    "    plt.ylabel('Voxel percentage')\n",
    "    plt.xlabel('Distance [mm]')\n",
    "    \n",
    "    plt.savefig('./plots/percentage_distance/smoothed/percentage_distance_subject_{}_rate_{}.png'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tresholds(man):\n",
    "    fmri_path = '../../data/fMRI/'\n",
    "    fmri = read_img(os.path.join(fmri_path, str(all_people[man])))\n",
    "    collage = np.concatenate([fmri.mean(-1)[..., i]/4095 for i in range(30)], axis = 0)\n",
    "    stats = get_statistics_train(man)\n",
    "    stats[stats > 2] = 2\n",
    "    \n",
    "    plt.figure(figsize=[20, 100])\n",
    "    plt.subplot(171)\n",
    "    plt.imshow(collage)\n",
    "    plt.title('mean brain')\n",
    "    plt.axis('off')\n",
    "    #plt.suptitle('Treshold Visualisation subject {} rate {}'.format(all_people[man], subject_rate[man]), fontsize=1)\n",
    "    for c, th in enumerate([.2, .4, .6, .8, 1]):\n",
    "        plt.subplot(172 + c)\n",
    "        collage_stats_tresh = np.concatenate([(stats[i]<th) for i in range(30)], axis = 0)\n",
    "        plt.imshow(collage_stats_tresh)\n",
    "        plt.title('treshold {}'.format(th))\n",
    "        plt.axis('off')\n",
    "    plt.savefig('./plots/treshold_visualization/Treshold Visualisation subject {} rate {}'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    plot_tresholds(i)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    plot_percentage_distance(i, 0.6)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_percentage_distance(man):\n",
    "    fmri_path = '../../data/fMRI/'\n",
    "    fmri = read_img(os.path.join(fmri_path, str(all_people[man])))\n",
    "    mean_fmri = fmri.mean(-1)\n",
    "    fmri_mask = mean_fmri > 66\n",
    "    \n",
    "    stats = get_statistics_train(man)\n",
    "    center_points = [14.5, 31.5, 31.5]\n",
    "    scores = {}\n",
    "    for i in range(30):\n",
    "        for j in range(64):\n",
    "            for k in range(64):\n",
    "                dist = (120/30*(i - center_points[0]))**2 \\\n",
    "                + (210/64*(j - center_points[1]))**2\\\n",
    "                + (210/64*(k - center_points[2]))**2\n",
    "                \n",
    "                \n",
    "                if fmri_mask[j, k, i]:\n",
    "                    if dist not in scores:\n",
    "                        scores[dist] = []\n",
    "                \n",
    "                    scores[dist].append(stats[i, j, k])\n",
    "\n",
    "    for key in scores:\n",
    "        scores[key] = np.mean(scores[key])\n",
    "\n",
    "    keys, values = [], []\n",
    "    for key in scores:\n",
    "        keys.append(np.sqrt(key))\n",
    "        values.append(scores[key])\n",
    "    values = np.array(values)\n",
    "    keys = np.array(keys)\n",
    "\n",
    "    argsort = np.argsort(keys)\n",
    "\n",
    "    plt.plot(keys[argsort], values[argsort])\n",
    "    plt.title(\"Voxel metric/Distance subject {}\".format(all_people[man][:-7]))\n",
    "    plt.ylabel('Voxel metric')\n",
    "    plt.xlabel('Distance [mm]')\n",
    "    plt.savefig('./plots/distance_metric/raw/metric_distance_subject_{}_rate_{}.png'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(keys[argsort], signal.savgol_filter(values[argsort], 53, 10))\n",
    "    plt.title(\"Savgol Filter for voxel metric/Distance subject {}\".format(all_people[man][:-7]))\n",
    "    plt.ylabel('Voxel metric')\n",
    "    plt.xlabel('Distance [mm]')\n",
    "    \n",
    "    plt.savefig('./plots/distance_metric/smoothed/metric_distance_subject_{}_rate_{}.png'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    plot_percentage_distance(i)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_clipped_loss(man):\n",
    "    stats = get_statistics_train(man)\n",
    "    fig, axis = plt.subplots(6, 5, figsize=[40, 40])\n",
    "    for slice_indx in range(30):\n",
    "        img = stats[slice_indx]\n",
    "        img[img > 2] = 2\n",
    "        im = axis[slice_indx%6, slice_indx//6].imshow(img, cmap='plasma_r', vmin=0, vmax=2)\n",
    "        plt.colorbar(im, ax=axis[slice_indx%6, slice_indx//6])\n",
    "    plt.savefig('./plots/clipped_metric/clipped_metric_subject{}_rate_{}.png'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_filter_treshold(man):\n",
    "    fmri_path = '../../data/fMRI/'\n",
    "    fmri = read_img(os.path.join(fmri_path, str(all_people[man])))\n",
    "    mean_fmri = fmri.mean(-1)\n",
    "\n",
    "    th_list = np.linspace(0, mean_fmri.max(), 1000)\n",
    "    acc_list = []\n",
    "    for th in th_list:\n",
    "        acc_list.append((mean_fmri > th).mean())\n",
    "    acc_list = np.array(acc_list)\n",
    "    #plt.figure(figsize=(20, 20))\n",
    "    l = len(th_list[th_list < 66])\n",
    "    plt.plot(th_list, acc_list, label='accepted voxels')\n",
    "    plt.plot(th_list[:l], acc_list[:l], label='filtered voxels')\n",
    "    plt.legend()\n",
    "    plt.title(\"filtered voxels / tresholds subject {}\".format(all_people[man]))\n",
    "    plt.ylabel(\"voxel persentage\")\n",
    "    plt.xlabel(\"tresholds\")\n",
    "    plt.savefig('./plots/distance_metric/voxel_tresholds/voxel_persentage_subject{}_rate_{}.png'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mask(man):\n",
    "    fmri_path = '../../data/fMRI/'\n",
    "    fmri = read_img(os.path.join(fmri_path, str(all_people[man])))\n",
    "    mean_fmri = fmri.mean(-1)\n",
    "    fmri_mask = mean_fmri > 66\n",
    "    \n",
    "    collage = np.concatenate([fmri.mean(-1)[..., i]/4095 for i in range(30)], axis = 0)\n",
    "    collage_mask = np.concatenate([fmri_mask[..., i] for i in range(30)], axis = 0)\n",
    "    \n",
    "    plt.figure(figsize=[20, 200])\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(collage)\n",
    "    plt.title('mean brain')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.imshow(collage_mask)\n",
    "    plt.title('mask')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('./plots/distance_metric/voxel_masks/mask_subject{}_rate_{}.png'.format(all_people[man][:-7], subject_rate[man]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center_points = [14.5, 31.5, 31.5]\n",
    "distances = np.zeros([30, 64, 64])\n",
    "for i in range(30):\n",
    "    for j in range(64):\n",
    "        for k in range(64):\n",
    "            dist = (120/30*(i - center_points[0]))**2 \\\n",
    "            + (210/64*(j - center_points[1]))**2\\\n",
    "            + (210/64*(k - center_points[2]))**2\n",
    "            distances[i, j, k] = dist\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    plot_clipped_loss(i)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    plot_mask(i)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(all_people)):\n",
    "    plot_filter_treshold(i)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cvf plots3d_1.tar ./plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
